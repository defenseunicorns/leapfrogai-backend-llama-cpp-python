[project]
name = "leapfrogai-backend-llama-cpp-py"
version = "0.2.0"

description = "llama-cpp-py based backend for LeapfrogAI"
authors = [{ name = "LeapfrogAI Authors", email = "ai@defenseunicorns.com" }]
license = { file = "LICENSE" }
readme = "README.md"
requires-python = "== 3.11.6"
dependencies = ["llama-cpp-python == 0.2.28", "leapfrogai == 0.4.0"]

[project.optional-dependencies]
dev = [
    "pip-tools",
    "pytest",
    "black",
    "isort",
    "huggingface_hub[cli,hf_transfer]",
    "nvidia-cublas-cu12 == 12.3.4.1",
    "nvidia-cuda-runtime-cu12 == 12.3.101",
]
gpu = ["nvidia-cublas-cu12 == 12.3.4.1", "nvidia-cuda-runtime-cu12 == 12.3.101"]

[tool.pytest.ini_options]
addopts = ["--import-mode=importlib"]

[tool.pip-tools]
generate-hashes = true
