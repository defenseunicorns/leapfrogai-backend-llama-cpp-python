[project]
name = "leapfrogai-backend-llama-cpp-py"
version = "0.1.0"

description = "llama-cpp-py based backend for LeapfrogAI"
authors = [{ name = "LeapfrogAI Authors", email = "ai@defenseunicorns.com" }]
license = { file = "LICENSE" }
readme = "README.md"
requires-python = ">=3.11.4"
dependencies = ["llama-cpp-python == 0.2.28", "leapfrogai == 0.4.0"]

[project.optional-dependencies]
dev = [
    "pip-tools",
    "pytest",
    "black",
    "isort",
    "nvidia-cublas-cu12",
    "nvidia-cuda-runtime-cu12",
]
gpu = ["nvidia-cublas-cu12", "nvidia-cuda-runtime-cu12"]

[tool.pytest.ini_options]
addopts = ["--import-mode=importlib"]

[tool.pip-tools]
generate-hashes = true
