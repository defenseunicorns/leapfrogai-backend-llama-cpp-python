[project]
name = "leapfrogai-backend-llama-cpp-py"
version = "0.1.0"

description = "llama-cpp-py based backend for LeapfrogAI"
authors = [{ name = "LeapfrogAI Authors", email = "ai@defenseunicorns.com" }]
license = { file = "LICENSE" }
readme = "README.md"
requires-python = ">=3.11.4, <3.12"
dependencies = [
    "llama-cpp-python == 0.2.28",
    "leapfrogai == 0.4.0"
]

[project.optional-dependencies]
dev = [
    "pip-tools == 7.3.0",
    "pytest == 7.4.3",
    "black == 23.11.0",
    "isort == 5.12.0",
    "nvidia-cublas-cu12 == 12.3.4.1",
    "nvidia-cuda-runtime-cu12 == 12.3.101",
]
gpu = ["nvidia-cublas-cu12 == 12.3.4.1", "nvidia-cuda-runtime-cu12 == 12.3.101"]

[tool.pytest.ini_options]
addopts = ["--import-mode=importlib"]

[tool.pip-tools]
generate-hashes = true
